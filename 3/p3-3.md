2XML简介

引文分析：引文有pdf和xml两种格式

这是用来专门制作网页的格式

3设计原则

数据转换不依赖平台

能够读写和验证

能人直接读

XML标准：

鲁棒性存在于多种语言中

能够集中于软件而非语言

免费

数据库操控这种语言

能够将外观和内容进行统一

4实践中的XML

树形结构是XML

python主要用的是键值对

5XML基础知识

开始标记，结束标记

面向文档和不面向文档两种类型

6XML资源

W3Schools

7解析XML

搜索python and XML
将整个XML读入内存中

元素遍历，能从一个树上找到具体的标签等去寻找

 8提取数据

假设文档用了某一个架构，那么提取丛中的数据内容

对作者的内容进行查找

```python
data["fnm"] = author.find('./fnm').text
data["snm"] = author.find('./snm').text
data["email"] = author.find('./email').text
**此时并不需要find,因为名字都是唯一的而且可以直接用文件内容进行处理**
```

9处理属性

iid此处定义了一个属性在标签中

```python
insr = author.findall('./insr')
    for i in insr:
        data["insr"].append(i.attrib["iid"])
```

10屏幕抓取简介

很多时候数据源来自多个并且要组合

11工作实例简介

从示例网站中找到数据统计的结果

需要完成大量的工作量

在此情况下，使用网站

12示例详情

得到最后的表

13数据在哪里

如何在网站找到需要请求的数据

多数情况下可以检查每个数据的元素

由此得到各种值的选项

由此找到一个类属性等等，得到需要得到的数据和数据背后的具体情况

14步骤

建立飞机值

建立机场值

之后发送HTTP请求数据下载

创建解析器

15提取实体

解析界面得到内容

用BS4中的BS

16构建http请求

利用浏览器（本身）获得请求方式

赋值然后放到一个里面，滚动到顶部然后发请求，会被编码为http格式

找到到底传送的数据是什么，发现比较复杂还得再看

17有多少表单元素

19练习使用bs

分析有几种值，然后考虑几种值会有接下来的重复出现

这些重复出现影响了值

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# Please note that the function 'make_request' is provided for your reference only.
# You will not be able to to actually use it from within the Udacity web UI.
# Your task is to process the HTML using BeautifulSoup, extract the hidden
# form field values for "__EVENTVALIDATION" and "__VIEWSTATE" and set the appropriate
# values in the data dictionary.
# All your changes should be in the 'extract_data' function
from bs4 import BeautifulSoup
import requests
import json

html_page = "page_source.html"


def extract_data(page):
    data = {"eventvalidation": "",
            "viewstate": ""}
    with open(page, "r") as html:
        soup = BeautifulSoup(html, "lxml")
        ev = soup.find(id="__EVENTVALIDATION")
        data["eventvalidation"] = ev["value"]

        vs = soup.find(id="__VIEWSTATE")
        data["viewstate"] = vs["value"]


    return data


def make_request(data):
    eventvalidation = data["eventvalidation"]
    viewstate = data["viewstate"]

    r = requests.post("http://www.transtats.bts.gov/Data_Elements.aspx?Data=2",
                    data={'AirportList': "BOS",
                          'CarrierList': "VX",
                          'Submit': 'Submit',
                          "__EVENTTARGET": "",
                          "__EVENTARGUMENT": "",
                          "__EVENTVALIDATION": eventvalidation,
                          "__VIEWSTATE": viewstate
                    })

    return r.text


def test():
    data = extract_data(html_page)
    assert data["eventvalidation"] != ""
    assert data["eventvalidation"].startswith("/wEWjAkCoIj1ng0")
    assert data["viewstate"].startswith("/wEPDwUKLTI")

    
test()
```

20请求中断

发现在区分之后仍然会有种情况是不能按照格式展现

21抓取的最佳做法

观察浏览器怎么做的

模拟格式

否则观察http

循环到第一步去尝试

22抓取解法

制作一个回话，并且观察回话是否是我们所需要的

此次下载得到了本地的数据

23小结

取得列表，下载所有数据，写一个解析器

然后得到
